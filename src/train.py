import src.File_Type_Validation as fv
import src.Data_Validation as dv
import src.database_operations as dboc
import src.preprocesing as prp
x = fv.File_Type_Validation("./src/dataset")
x.createCsvDir()
x.convertToCsv()
zz =dv.DataValidation()
zz.makeFinalCsvDirectory(zz.finalCsvTrain)
zz.makeFinalCsvDirectory(zz.finalCsvTest)
z,g,dic = zz.verifyingSchema(zz.schemaPath)
a= zz.validateColumnLength(g,zz.goodCsvPath)
b = zz.validateMissingValuesInWholeColumn(zz.goodCsvPath)
d= zz.getColumnName(zz.schemaPath)
e=zz.addColumnNames(d, zz.goodCsvPath)
f = zz.addQuotesToString(dic)
db = dboc.CassandraOperations()
db.databaseConnection()
db.createPreprocessedCsvDirectory(db.combinedTrain)
db.deleteTable('train')
db.createTable('train', db.schemaPath)
db.insertValidatedData(db.finalCsvTrain, "train", db.schemaPath)
db.fetch(db.combinedTrain, "train",  db.schemaPath)

pre = prp.Preprocessing()
pre.createPreprocessedDirectory()
pre.readCsv(pre.trainCsv)
pre.dropUnnecessaryColumns()
pre.replaceWithNan()
pre.mappingCategoricalColumns()
pre.getDummies()
pre.labelEncoding()
pre.exportCsv(pre.trainCsv)
